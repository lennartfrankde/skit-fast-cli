# LiteLLM Configuration
# See https://docs.litellm.ai/docs/proxy/configs for more details

model_list:
  # OpenAI Models
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: ${OPENAI_API_KEY}
  
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: ${OPENAI_API_KEY}

  # Anthropic Models
  - model_name: claude-3-sonnet
    litellm_params:
      model: anthropic/claude-3-sonnet-20240229
      api_key: ${ANTHROPIC_API_KEY}

  # Add more models as needed

# General settings
general_settings:
  master_key: ${LITELLM_MASTER_KEY}
  database_url: ${DATABASE_URL}
  
# Optional: Enable logging
litellm_settings:
  success_callback: ["langfuse"]  # or other callbacks
  failure_callback: ["langfuse"]

# Optional: Rate limiting
router_settings:
  routing_strategy: "least-busy"